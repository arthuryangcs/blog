---
title: Hadoop MapReduce 详解
date: 2017-02-28 15:26:26
tags: 
 - Hadoop
 - MapReduce
categories: Hadoop
---

这里我们详细介绍一下 Hadoop 中 MapReduce 的执行流程，这可以帮助我们写出更加高性能的 MapReduce 程序。

<!-- more -->

## MapReduce 作业（job）剖析

下图展示了一个 MapReduce 作业的整体流程：

{% asset_img mapreduce-job.png MapReduce 作业整体流程 %}

由五个独立的部分组成：

* 客户端，提交 MapReduce 任务
* YARN 资源管理器，负责协调集群的计算资源
* YARN 节点管理器，负责运行和监控集群机器上的计算容器
* MapReduce 应用主节点，负责协调 MapReduce 作业中的任务
* 分布式文件系统，这里通常是 HDFS，用来在实体间分享作业文件

### 作业提交

由客户端来提交一个新的作业（图中步骤 1），提交过程主要由以下几部分组成：

* 向资源管理器申请一个新的应用 ID，作为 MapReduce 作业 ID（步骤 2）。
* 检查作业的输出规范。若输出文件夹没有指定或者已经存在则返回错误，不提交作业。
* 计算作业输入文件划分，如果无法计算（例如输入路径不存在）则返回错误，不提交作业。
* 复制作业需要的资源到分布式文件系统中，以作业 ID 作为文件夹名称（步骤 3）。其中包括作业的 JAR 包、配置文件、输入文件划分。
* 向资源管理器提交任务（步骤 4）。

### 作业初始化

当资源管理器接收到客户端提交的任务，它将请求发往 YARN 调度者。调度者给作业分配一个容器，资源管理器在节点管理器的管理下运行这个应用（步骤 5a 和步骤 5b）。

应用主节点初始化作业，建立一定数量的记录对象来追踪任务的进度，来接收任务进度和结束报告（步骤 6）。接着，它从分布室文件系统中获取输入文件划分（步骤 7），为每个划分建立 Map 任务，和一定数量的 Reduce任务（由 *mapreduce.job.reduces* 属性设定）。

应用主节点必须确定如何执行任务。如果作业比较小的话，应用主节点会选择在同一个 JVM 中串行运行任务，这被称作 *uberized*，这个任务被称作 *uber* 任务 ；否则则会在多个节点上并行执行任务。 uber 任务可降低任务的延迟。

### 任务分配

如果作业没有按照 uber 模式执行，应用主节点会向资源管理器请求 Map 任务和 Reduce 任务所需要的容器（步骤 8）。Map 任务相比 Reduce 任务先被创造，并且有更高的优先级。所有 Map 任务完成后才会开始排序阶段，5% 以上的 Map 任务执行完后才会开始 Reduce 任务。

Reduce 任务可执行在集群中的任何机器上，但 Map 任务会尽量在数据所在机器上执行，或在相同机器机架上的机器执行，这是为了减少网络带宽的使用。

请求同时也会为任务分配内存和 CPU，默认情况狂下，每一个 Map 任务或者 Reduce 任务分配 1024 MB 的内存和一个虚拟节点。也可通过以下属性进行配置：mapreduce.map.memory.mb、mapreduce.reduce.memory.mb、mapreduce.map.cpu.vcores、mapreduce.reduce.cpu.vcore。

### 任务执行

一旦任务通过资源管理器分配到某一节点的容器及资源，任务管理器就会联系节点管理器开始执行容器（步骤 9a 和步骤 9b）。在任务开始之前，节点会从分布式缓存中获取需要的配置文件和 JAR 包（步骤 10）。最后，节点执行任务（步骤 11）。


